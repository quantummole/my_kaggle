{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning using VGG and fully connected layers is trained to classify dog breeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jan 19 14:59:05 2018\n",
    "\n",
    "@author: QuantumMole\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import vgg\n",
    "import pandas as pd\n",
    "from skimage import io,filters,transform\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "def max_pool(x,shape,stride):\n",
    "    return tf.layers.max_pooling2d(inputs=x, pool_size=shape, strides=stride)\n",
    "\n",
    "\n",
    "def conv2_layer(input,num_filters,shape,stride,scale_l1 = 0.1,scale_l2=0.1):\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(scale_l1,scale_l2)\n",
    "    y= tf.layers.conv2d(inputs = input,kernel_size=shape,\n",
    "                     filters = num_filters,activation=None,\n",
    "                     padding='same',use_bias=True,strides=stride,kernel_regularizer = regularizer)\n",
    "    return y\n",
    "\n",
    "def full_layer(input, size,activation):\n",
    " regularizer = tf.contrib.layers.l1_l2_regularizer(0.1,1.0)\n",
    " return tf.layers.dense(inputs=input, units=size, activation=activation,kernel_regularizer = regularizer,bias_regularizer = regularizer)\n",
    "\n",
    "def droput_layer(input,keep_prob) :\n",
    "    return tf.nn.dropout(input, keep_prob=keep_prob)\n",
    "def batchnorm_layer(input) :\n",
    "    return tf.layers.batch_normalization(inputs=input)\n",
    "\n",
    "def getTrainData() : \n",
    "    labels = pd.read_csv('./labels.csv')\n",
    "    breeds = pd.read_csv('./breeds.csv')\n",
    "    y_augmented = labels.set_index('breed').join(breeds.set_index('breed')).set_index('id')\n",
    "    pictures = [x for x in os.listdir('./train') if 'jpg' in x]\n",
    "    y = np.array([y_augmented.get_value(x.replace(\".jpg\",\"\"),'breed_id') for x in pictures])\n",
    "    #z = np.array([transform.resize(io.imread(\"./train/{}\".format(x)),(256,256)) for x in pictures])\n",
    "    return np.array(pictures),y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pictures,Y = getTrainData()\n",
    "vgg_model = vgg.VGG16()\n",
    "BATCH_SIZE = 8\n",
    "image_data_max = []\n",
    "image_data_mean = []\n",
    "pictures_train = pictures[0:int(0.8*len(pictures))]\n",
    "pictures_valid = pictures[int(0.8*len(pictures)):]  \n",
    "train_Y = Y[0:int(0.8*len(pictures))]\n",
    "valid_Y = Y[int(0.8*len(pictures)):]\n",
    "pictures_test = np.array([x for x in os.listdir('./test') if 'jpg' in x])\n",
    "def loadImages(image_indices,pics,fold,valid=False) :\n",
    "    def preprocess(im) :\n",
    "        z = np.random.randint(0,1)\n",
    "        if z == 1:\n",
    "            x = np.random.randint(0,223)\n",
    "            y =np.random.randint(0,223)\n",
    "            im[x:x+16,y:y+16] = 0           \n",
    "        return im\n",
    "    if not valid :\n",
    "        z = np.array([preprocess(transform.resize(io.imread(\"./{}/{}\".format(fold,x)),(128,128))) for x in pics[image_indices]])\n",
    "    else :\n",
    "        z = np.array([transform.resize(io.imread(\"./{}/{}\".format(fold,x)),(128,128)) for x in pics[image_indices]])\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_DIR=\"/home/QuantumMole/tensorflow/DogBreed\"\n",
    "with vgg_model.graph.as_default() :\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    final_layer1 = tf.nn.relu(batchnorm_layer(conv2_layer(vgg_model.get_layer_tensors([12])[0],256,(1,1),(1,1),1.0,0.0)))\n",
    "    final_layer2 = max_pool(tf.nn.relu(batchnorm_layer(conv2_layer(final_layer1,256,(3,3),(1,1),1.0,0.0))),(2,2),(2,2))\n",
    "    final_layer = tf.nn.relu(batchnorm_layer(conv2_layer(final_layer2,512,(3,3),(1,1),0.0,1.0)))\n",
    "    final_layer_flat = tf.reshape(final_layer,(-1,512*16))\n",
    "    fc_1 = droput_layer(tf.nn.relu(batchnorm_layer(full_layer(final_layer_flat,1024,None))),keep_prob)\n",
    "    fc_2 = droput_layer(tf.nn.relu(batchnorm_layer(full_layer(fc_1,1024,None))),keep_prob)\n",
    "    fc_3 = droput_layer(tf.nn.relu(batchnorm_layer(full_layer(fc_2,1024,None))),keep_prob)\n",
    "    output = full_layer(fc_3,120,tf.nn.relu)        \n",
    "    oimage_batch = tf.placeholder(tf.int32,shape=(None,),name = \"image_output\")\n",
    "    output_labels = tf.one_hot(oimage_batch,120)\n",
    "    output_probs = tf.nn.softmax(output)\n",
    "    loss = tf.losses.softmax_cross_entropy(output_labels,output)\n",
    "    train_step = tf.train.AdamOptimizer(1e-5).minimize(loss)\n",
    "    with tf.name_scope('summaries'):\n",
    "        tf.summary.scalar('Loss', loss)\n",
    "    summary = tf.summary.merge_all()\n",
    "    validation_loss = tf.summary.scalar('validation_loss', loss)\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    with tf.Session() as sess:\n",
    "            writer = tf.summary.FileWriter('{}/graphs'.format(LOG_DIR),sess.graph)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(0,30*len(pictures_train),len(pictures_train)) :\n",
    "                for i in range(0,len(pictures_train),BATCH_SIZE) :\n",
    "                    train_data_indexes = range(i,min(len(pictures_train),i+BATCH_SIZE))\n",
    "                    train_batch_X = loadImages(train_data_indexes,pictures_train,'train')\n",
    "                    train_batch_Y = train_Y[train_data_indexes]\n",
    "                    vgg_dict = {**vgg_model.create_feed_dict(train_batch_X),oimage_batch:train_batch_Y,keep_prob:0.5}\n",
    "                    _,loss1,summ= sess.run([train_step,loss,summary],feed_dict=vgg_dict)\n",
    "                    writer.add_summary(summ,epoch+i)\n",
    "                    valid_indices = [i for i in range(len(pictures_valid))]\n",
    "                    shuffle(valid_indices)\n",
    "                    valid_indices = valid_indices[0:32]\n",
    "                    train_batch_X = loadImages(valid_indices,pictures_train,'train',True)\n",
    "                    train_batch_Y = valid_Y[valid_indices]\n",
    "                    vgg_dict = {**vgg_model.create_feed_dict(train_batch_X),oimage_batch:train_batch_Y,keep_prob:1.0}\n",
    "                    val_loss= sess.run(validation_loss,feed_dict=vgg_dict)\n",
    "                    writer.add_summary(val_loss,epoch+i)\n",
    "                    if i%96 == 0:\n",
    "                        saver.save(sess, \"{}/model.ckpt-{}-{}\".format(LOG_DIR,epoch,i))\n",
    "                    print(epoch+i,loss1)\n",
    "                indices = shuffle([i for i in range(len(pictures_train))])\n",
    "                pictures_train = pictures_train[indices].reshape(-1)\n",
    "                train_Y = train_Y[indices].reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(0,len(pictures_test),BATCH_SIZE) :\n",
    "                train_data_indexes = range(i,min(len(pictures_test),i+BATCH_SIZE))\n",
    "                train_batch_X = loadImages(train_data_indexes,pictures_test,'test',True)\n",
    "                vgg_dict = {**vgg_model.create_feed_dict(train_batch_X),keep_prob:1.0}\n",
    "                out = sess.run(output_probs,feed_dict=vgg_dict)\n",
    "                image_data_max.append(out)\n",
    "                print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_ans = np.vstack(image_data_max)\n",
    "filenames = np.array([x.replace(\".jpg\",\"\") for x in pictures_test])\n",
    "filenames.shape = (filenames.shape[0],1)\n",
    "final_ans_norm = np.array([x/np.sum(x) for x in final_ans])\n",
    "z = np.hstack([final_ans_norm,filenames])\n",
    "breeds = pd.read_csv('./breeds.csv')\n",
    "breeds.set_index('breed_id')\n",
    "col_names = [breeds.get_value(i,'breed') for i in range(120)] +['id']\n",
    "t = pd.DataFrame(data=z,columns = col_names)\n",
    "t = t.set_index('id')\n",
    "t.to_csv(\"./output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
